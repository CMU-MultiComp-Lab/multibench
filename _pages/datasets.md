---
layout: datasets
permalink: /datasets/
title: Datasets
---

MultiBench datasets:

Affective Computing:

1. MUStARD: Castro et al., [Towards multimodal sarcasm detection (an _obviously_ perfect paper)](https://arxiv.org/abs/1906.01815), ACL 2019

2. CMU-MOSI: Zadeh et al., [MOSI: multimodal corpus of sentiment intensity and subjectivity analysis in online opinion videos](https://arxiv.org/abs/1606.06259), IEEE Intelligent Systems 2016 

3. UR-FUNNY: Hasan et al., [UR-FUNNY: A multimodal language dataset for understanding humor](https://arxiv.org/abs/1904.06618), EMNLP 2019

4. CMU-MOSEI: Zadeh et al., [Multimodal language analysis in the wild: CMU-MOSEI dataset and interpretable dynamic fusion graph](https://www.aclweb.org/anthology/P18-1208/), ACL 2018

Healthcare:

1. MIMIC: Johnson et al., [MIMIC-III, a freely accessible critical care database](https://pubmed.ncbi.nlm.nih.gov/27219127/), Nature Scientific Data 2016

Robotics:

1. MuJoCo PUSH: Lee et al., [Multimodal sensor fusion with differentiable filters](https://arxiv.org/abs/2010.13021), IROS 2020

2. Vision&Touch: Lee et al., [Making sense of vision and touch: Self-supervised learning of multimodal representations for contact-rich tasks](https://arxiv.org/abs/1810.10191), ICRA 2019

Finance:

1. Stocks-F&B consists of $8 selected stocks from S&P 500 stocks categorized by GICS as Restaurants or Packaged Foods & Meats. We select MCD, SBUX, HSY, and HRL for initial experiments on this dataset, record their opening prices and preprocess the data.

2. Stocks-Health consists of 63 selected stocks from S&P $500$ stocks categorized by GICS as Health Care. We select MRK, WST, CVS, MCK, ABT, UNH, and TFX for initial experiments on  this dataset, record their opening prices, and preprocess the data.

3. Stocks-Tech consists of 100 selected stocks from S&P 500 stocks categorized by GICS as Information Technology or Communication Services. We select AAPL, MSFT, AMZN, INTC, AMD, and MSI for initial experiments on this dataset, record their opening prices, and preprocess the data.

HCI:

1. ENRICO: Leiva et al., [Enrico: A dataset for topic modeling of mobile UI designs](https://userinterfaces.aalto.fi/enrico/resources/enrico.pdf), MobileHCI 2020

Multimedia:

1. MM-IMDb: Arevalo et al., [Gated multimodal units for information fusion](https://arxiv.org/abs/1702.01992), ICLR workshop 2017

2. AV-MNIST: Vielzeuf et al., [Centralnet: a multilayer approach for multimodal fusion](https://arxiv.org/abs/1808.07275), ECCV workshop 2018

3. Kinetics-400: Kay et al., [The kinetics human action video dataset](https://arxiv.org/abs/1705.06950), arXiv 2017
